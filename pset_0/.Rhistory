norm <- percept$norm
classes <- classify(sample, norm)
tab <- table(class, classes)
tab
if(all(class==classes)){
print("works")
}
test_data <- fakedata(z, 100)
sample <- test_data$S
class <- test_data$y
classes <- classify(sample, norm)
tab <- table(class, classes)
tab
print("ending")
help("colSums")
help("sum")
sum("True", "false", "true")
sum(true, false, true")
sum(true, false, true)
sum("true", "false", "false")
sum(TRUE, FALSE)
#Inputs
#w:  w[1:d] is the normal vector of a hyperplane,
#    w[d+1] = -c is the negative offset parameter.
#n: sample size
#Outputs
#S: n by (d+1) sample matrix with last col 1
#y: vector of the associated class labels
fakedata <- function(w, n){
if(! require(MASS))
{
install.packages("MASS")
}
if(! require(mvtnorm))
{
install.packages("mvtnorm")
}
require(MASS)
require(mvtnorm)
# obtain dimension
d <- length(w)-1
# compute the offset vector and a Basis consisting of w and its nullspace
offset <- -w[length(w)] * w[1:d] / sum(w[1:d]^2)
Basis <- cbind(Null(w[1:d]), w[1:d])
# Create samples, correct for offset, and extend
# rmvnorm(n,mean,sigme) ~ generate n samples from N(0,I) distribution
S <- rmvnorm(n, mean=rep(0,d),sigma = diag(1,d)) %*%  t(Basis)
S <- S + matrix(rep(offset,n),n,d,byrow=T)
S <- cbind(S,1)
# compute the class assignments
y <- as.vector(sign(S %*% w))
# add corrective factors to points that lie on the hyperplane.
S[y==0,1:d] <- S[y==0,1:d] + runif(1,-0.5,0.5)*10^(-4)
y = as.vector(sign(S %*% w))
return(list(S=S, y=y))
} # end function fakedata
#inputs:
# S = Linearly seperaable data
# z = normal vector to hyperplane and offset
#outputs:
# classification = a vector containing classification for each point
classify <- function(S,z){
classification =  sign(S %*% z)
for(i in length(classification))
{
if(classification[i]==0)
{
classification[i]<-1
}
}
return(classification)
}
# inputs:
# S = sample of linearlly seperable data in a matrix
# y = classification for each data point
# outputs:
# norm = normal vector of the hyperplane
# norm_history = matrix with the history of the normal vector
perceptrain <- function(S,y){
#reverse sample for neg class
S[y==-1,4] <- -S[y==-1,4]
#pick random vector as starting line (since data is random any number 1 to n works)
norm <-  S[1,]
k <- 1
norm_history <- norm
classifications <- S %*% norm
#Find number of mistakes
mistakes <- (classifications <= 0)
cost = sum(mistakes)
while(cost > 0){
#note colSum doesn't work when mistakes is one-dim
if(cost==1){
norm = norm + 1/k*S[mistakes,]
}else{
norm = norm + 1/k*colSums(S[mistakes,])
}
k <- k+1
#evaluate new line and add to history
classifications <- S %*% norm
rbind(norm_history, norm)
#check for mistakes and calc cost
mistakes <- (classifications<=0)
cost = sum(mistakes)
}
output <- list(norm=norm, norm_history=norm_history)
return(output)
}
print("starting")
z <- runif(4)
train_data <- fakedata(z, 100)
sample <- train_data$S
class <- train_data$y
percept <- perceptrain(sample, class)
help("read.table")
data <- read.table("uspsdata.txt")
class <- read.table("uspscl.txt")
data
class
#Name: Ethan Grant
#uni: erg2145
#class: Stats 4400
#Hw2
data <- read.table("uspsdata.txt")
class <- read.table("uspscl.txt")
data
class
#Name: Ethan Grant
#uni: erg2145
#class: Stats 4400
#Hw2
data <- read.table("uspsdata.txt")
class <- read.table("uspscl.txt")
data
class
#Name: Ethan Grant
#uni: erg2145
#class: Stats 4400
#Hw2
data <- read.table("uspsdata.txt")
class <- read.table("uspscl.txt")
data
class
data <- read.table("uspsdata.txt")
data <- read.table("uspsdata.txt")
class <- read.table("uspscl.txt")
data <- read.table("uspsdata.txt")
data <- read.table("uspsdata.txt")
data <- read.table("uspsdata.txt")
data <- read.table("uspsdata.txt")
B <- matrix( c(2,4,3,1,5,7), nrow=3, ncol=2)
View(B)
order(B[,1])
order(B[1,])
B
B<- order(B[,1])
B
help("order")
B <- matrix( c(2,4,3,1,5,7), nrow=3, ncol=2)
index<- order(B[,1])
b_new <- B[index,1]
b_new
help("cumsum")
sort(B[,1])
B[,1]
help("duplicated")
test <- c(1, 5, 7, 9, 10)
help("sort")
order(test)
help("order")
order(test[])
temp <- order(test[])
temp
test
test <- c(1, 5, 7, 9, 10)
test
dex <- order(test)
dex <- order(test)
dex
test <- c(1, 5, 7, 9, 10)
test
order(test)
test
test <- c(1, 5, 7, 9, 10)
order(test[1])
test
B <- matrix( c(2,4,3,1,5,7), nrow=3, ncol=2)
index<- order(B[,1])
index
help("duplicated")
x <- c(-1, 2, 3, -4)
(x<0)
(x<0)*2
(x<0)*2-1
x> 1
n = [4 8 16 256]
n = [4 8 16 256]
n <- (4, 8, 16, 256)
n <- c(4, 8, 16, 256)
exprnd?
;
help("exprnd")
data <- rexp(256, 1)
data
sum(data)
exp(log(gamma(x, alpha+ 256, .2+sum(data))))
exp(log(gamma(data, alpha+ 256, .2+sum(data))))
theta <- 1
n <- c(4, 8, 16, 256)
alpha <- 2
beta <- .2
data <- rexp(256, 1)
exp(log(gamma(data, alpha+ 256, .2+sum(data))))
help(gamma)
len(data)
dim(data)
length(data)
alpha_list <- rep(0, 256)
alpha[1] <- 2
alpha_list
alpha_list[1] <- 2
alpha_list
alpha <- rep(0, 256)
alpha[1] <- 2
beta <- rep(0, 256)
beta[1] <- .2
theta <- 1
alpha <- 2
beta <- .2
dgamma(data, alpha + 256, 1/(beta+sum(x[1:256]))
)
dgamma(data, alpha + 256, 1/(beta+sum(data[1:256])
)
)
dgamma(data, alpha + 256, (beta+sum(data[1:256])))
ggplot(dgamma(data, alpha + 256, (beta+sum(data[1:256]))))
plot(dgamma(data, alpha + 256, (beta+sum(data[1:256]))))
theta <- 1
alpha <- 2
beta <- .2
n <- c(4, 8, 16, 256)
data <- rexp(256, 1)
for (i in 1:4) {
sum <- sum(ex[1:n[i]])
x_n <- n[i]
new_alph <- alpha + n
new_beta <- beta + sum
plot <- dgamma(g_points, rate = new_beta, shape = new_alph)
if (i == 1) plot(g_points, g, ylim = range(0, 7), xlab = "", ylab = "")
else points(g_points, g, col = i*10)
}
theta <- 1
alpha <- 2
beta <- .2
n <- c(4, 8, 16, 256)
points <- seq(0, 4, 0.01)
data <- rexp(256, 1)
for (i in 1:4) {
sum <- sum(ex[1:n[i]])
x_n <- n[i]
new_alph <- alpha + n
new_beta <- beta + sum
plot <- dgamma(points, rate = new_beta, shape = new_alph)
if (i == 1) plot(points, plot, ylim = range(0, 7), xlab = "", ylab = "")
else points(points, plot, col = i*10)
}
theta <- 1
alpha <- 2
beta <- .2
n <- c(4, 8, 16, 256)
points <- seq(0, 4, 0.01)
data <- rexp(256, 1)
for (i in 1:4) {
plot <- dgamma(points, rate = beta + sum(ex[1:n[i]]), shape = alpha + n[i])
if (i == 1)
plot(points, plot, ylim = range(0, 7), xlab = "", ylab = "")
else points(points, plot, col = i*10)
}
forsum <- rep(256,1)
forsum
theta <- 1
alpha <- 2
beta <- .2
n <- c(4, 8, 16, 256)
points <- seq(0, 4, 0.01)
data <- rexp(256, 1)
forsum <- rep(256,1)
for (i in 1:4) {
plot <- dgamma(points, rate = beta + sum(forsum[1:n[i]]), shape = alpha + n[i])
if (i == 1)
plot(points, plot, ylim = range(0, 7), xlab = "", ylab = "")
else points(points, plot, col = i*10)
}
theta <- 1
alpha <- 2
beta <- .2
n <- c(4, 8, 16, 256)
plot_points <- seq(0, 4, 0.01)
data <- rexp(256, 1)
forsum <- rep(256,1)
for (i in 1:4) {
plot <- dgamma(points, rate = beta + sum(forsum[1:n[i]]), shape = alpha + n[i])
if (i == 1)
plot(plot_points, plot, ylim = range(0, 7), xlab = "", ylab = "")
else points(plot_points, plot, col = i*10)
}
plot <- dgamma(points, rate = beta + sum(forsum[1:n[i]]), shape = alpha + n[i])
plot <- dgamma(points, rate = beta + sum(forsum[1:4]), shape = alpha + 4)
# Raghav Bansal
# rb3033
# Stat W4400
# HW05 program code
# Problem 2: Conjugacy
# g.
alpha <- 2
beta <- 0.2
n_observations <- c(4, 8, 16, 256)
g_points <- seq(0, 4, 0.01)
forsum <- rexp(256, rate = 1)
for (i in 1:length(n_observations)) {
sum_xn <- sum(forsum[1:n_observations[i]])
n <- n_observations[i]
a <- alpha + n
b <- beta + sum_xn
g <- dgamma(g_points, rate = b, shape = a)
if (i == 1) plot(g_points, g, ylim = range(0, 7), xlab = "", ylab = "")
else points(g_points, g, col = i*10)
}
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
source('C:/Users/Ethan/Desktop/Columbia/Junior Spring/Stat ML/hw5/hw_5.R', echo=TRUE)
?plot
my_mean_vector(ran_sample)
install.package('foreign')
library(foreign)
setwd('C:\Users\Ethan\Desktop\Columbia\Senior_Fall\Advanced_Econometrics')
data-read.dta('TeachingRatings.dta')
head(data)
y = data$course_eval
x = cbind(1,data$beauty,data$age)
colnames(X)=c('intercept','beauty','age')
install.package('foreign')
library(foreign)
setwd('C:\Users\Ethan\Desktop\Columbia\Senior_Fall\Advanced_Econometrics')
data-read.dta('TeachingRatings.dta')
head(data)
y = data$course_eval
x = cbind(1,data$beauty,data$age)
colnames(X)=c('intercept','beauty','age')
install.package('foreign')
install.packages(’foreign’)
install.packages('foreign’)
d
d
d
a
dv
ad
vadsvasdgvqwefv
;
;
''
:
""
)
)
)
source('C:/Users/Ethan/Desktop/Columbia/Senior_Fall/Advanced_Econometrics/pset_0.R', echo=TRUE)
install.packages('foreign')
install.packages("foreign")
library(foreign)
setwd('C:\Users\Ethan\Desktop\Columbia\Senior_Fall\Advanced_Econometrics')
wd
getwd()
setwd('..\Desktop\Columbia\Senior_Fall\Advanced_Econometrics')
setwd('C:/Users/Ethan/Desktop/Columbia/Senior_Fall/Advanced_Econometrics')
getwd()
data-read.dta('TeachingRatings.dta')
data-read.dta('TeachingRatings.dta')
setwd('C:/Users/Ethan/Desktop/Columbia/Senior_Fall/Advanced_Econometrics/')
data-read.dta('TeachingRatings.dta')
data=read.dta('TeachingRatings.dta')
head(data)
plot(y, data$beauty)
y = data$course_eval
x = cbind(1,data$beauty,data$age)
colnames(X)=c('intercept','beauty','age')
plot(y, data$beauty)
plot(y, x$beauty)
X= cbind(1,data$beauty,data$age)
colnames()=c('intercept','beauty','age')
colnames(X)=c('intercept','beauty','age')
plot(y, x$beauty)
Y = data$course_eval
X= cbind(1,data$beauty,data$age)
colnames(X)=c('intercept','beauty','age')
plot(Y, X$beauty)
plot(Y, X['beauty'])
X['beauty']
X= cbind(1,data$beauty,data$age)
colnames(X)=c('intercept','beauty','age')
X['beauty']
X
X['beauty',]
X[,'beauty']
plot(Y, X[,'beauty'])
?solve
ginv(t(X)%*%X)%*%t(X)%*%Y
library("MASS", lib.loc="C:/Program Files/R/R-3.2.2/library")
ginv(t(X)%*%X)%*%t(X)%*%Y
beta <- ginv(t(X)%*%X)%*%t(X)%*%Y
beta
beta_hat <- ginv(t(X)%*%X)%*%t(X)%*%Y
residual <- Y - X%*%beta_hat
residual
mean(residual)
variance(residual)
mean(residual)
var(residual)
M <- diag(length(Y))-X%*%ginv(t(X)%*%X)%*%t(X)
M
var(Y)
SS_res <- sum(residual^2)
SS-res <- sum(residual^2)
SS_total <- sum((y-mean(y)^2))
r_squared <- 1-SS_res/SS_total
test <- lm(Y ~ X[,'beauty']+X[,'age'])
test
beta_hat
X_age <- cbind(1, data$age)
X_beauty <- cbind(1, data$beauty)
residuals_age <- Y-X%*%beta_hat_age
X_age <- cbind(1, data$age)
beta_hat_age <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%Y
residuals_age <- Y-X%*%beta_hat_age
beta_hat_beauty <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%X['beauty']
X['beauty']
beta_hat_beauty <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%X[,'beauty']
residsuals_beauty <- x[,'beauty']-X_age%*%beta_hat_beauty
residsuals_beauty <- X[,'beauty']-X_age%*%beta_hat_beauty
residuals_age <- ginv(t(residsuals_beauty)%*%residsuals_beauty)%*%t(residsuals_beauty)%*%Y
X_age <- cbind(1, data$age)
beta_hat_age <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%Y
residuals_age <- Y-X%*%beta_hat_age
beta_hat_beauty <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%X[,'beauty']
residsuals_beauty <- X[,'beauty']-X_age%*%beta_hat_beauty
beta_2 <- ginv(t(residsuals_beauty)%*%residsuals_beauty)%*%t(residsuals_beauty)%*%residuals_age
X_age <- cbind(1, data$age)
beta_hat_age <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%Y
residuals_age <- Y-X%*%beta_hat_age
beta_hat_age <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%Y
beta_hat_age
residuals_age <- Y-X_age%*%beta_hat_age
beta_hat_beauty <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%X[,'beauty']
residsuals_beauty <- X[,'beauty']-X_age%*%beta_hat_beauty
beta_2 <- ginv(t(residsuals_beauty)%*%residsuals_beauty)%*%t(residsuals_beauty)%*%residuals_age
beta_2
beta_hat
M1 = I - X1%*%ginv(t(X1)%*%X1)%*%t(X1)
Y = data$course_eval
X1 = cbind(1, data$age)
X0 = data$beauty
I = diag(length(y))
M1 = I - X1%*%ginv(t(X1)%*%X1)%*%t(X1)
beta = ginv(t(M1%*%X2)%*%M1%*%X2)%*%t(M1%*%X2)%*%M1%*%Y
beta = ginv(t(M1%*%X0)%*%M1%*%X0)%*%t(M1%*%X0)%*%M1%*%Y
beta
solve_matrix = matrix(c(1, 2, 3, 4,2,1,2,3,3,2,1,2,4,3,2,1),nrow=4,ncol=4)
solve_matrix
solve(solve_matrix, matrix(c(5,6,7,8),nrow=4,ncol=1))
ran_sample = rnorm(20, mean=1, sd=2)
mean(ran_sample)
var(ran_sample)
hist(ran_sample)
my_mean_vector(ran_sample)
install.packages('foreign')
library(foreign)
install.packages("foreign")
setwd('C:/Users/Ethan/Desktop/Columbia/Senior_Fall/Advanced_Econometrics/')
data=read.dta('TeachingRatings.dta')
head(data)
Y = data$course_eval
colnames(X)=c('intercept','beauty','age')
plot(Y, X[,'beauty'])
X= cbind(1,data$beauty,data$age)
beta_hat <- ginv(t(X)%*%X)%*%t(X)%*%Y
beta_hat
residual <- Y - X%*%beta_hat
residual
mean(residual)
var(residual)
M <- diag(length(Y))-X%*%ginv(t(X)%*%X)%*%t(X)
M
var(Y)
SS_res <- sum(residual^2)
SS_total <- sum((y-mean(y)^2))
r_squared <- 1-SS_res/SS_total
r_squared
X_age <- cbind(1, data$age)
beta_hat_age <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%Y
residuals_age <- Y-X_age%*%beta_hat_age
beta_hat_beauty <- ginv(t(X_age)%*%X_age)%*%t(X_age)%*%X[,'beauty']
residsuals_beauty <- X[,'beauty']-X_age%*%beta_hat_beauty
beta_2 <- ginv(t(residsuals_beauty)%*%residsuals_beauty)%*%t(residsuals_beauty)%*%residuals_age
